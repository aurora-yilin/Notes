# Hadoop小文件解决方案

***

> 小文件优化方向
>
> （1）在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS。
>
> （2）在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并。
>
> （3）在MapReduce处理时，可采用CombineTextInputFormat提高效率。
>
> （4）开启uber模式，实现jvm重用

***

## 1.uber模式

> Uber运行模式对小作业进行优化，不会给每个任务分别申请分配Container资源，这些小任务将统一在一个Container中按照先执行map任务后执行reduce任务的顺序串行执行。那么什么样的任务，mapreduce框架会认为它是小任务呢？
>
> - map任务的数量不大于mapreduce.job.ubertask.maxmaps参数（默认值是9）的值;
> - reduce任务的数量不大于mapreduce.job.ubertask.maxreduces参数（默认值是1）的值;
> - 输入文件大小不大于mapreduce.job.ubertask.maxbytes参数（默认为1个Block的字节大小）的值；
> - map任务和reduce任务需要的资源量不能大于MRAppMaster（mapreduce作业的ApplicationMaster）可用的资源总量；也就是说yarn.app.mapreduce.am.resource.mb必须大于mapreduce.map.memory.mb和mapreduce.reduce.memory.mb以及yarn.app .mapreduce.am.resource.cpu-vcores必须大于mapreduce.map.cpu.vcores和mapreduce.reduce.cpu.vcores以启用ubertask。 
>
> 参数mapreduce.job.ubertask.enable用来控制是否开启Uber运行模式，默认为false。

***

### 1.1开启uber模式

> 开启uber模式，实现jvm重用。默认情况下，每个Task任务都需要启动一个jvm来运行，如果Task任务计算的数据量很小，我们可以让同一个Job的多个Task运行在一个Jvm中，不必为每个Task都开启一个Jvm。
>
> ```xml
> <!--  开启uber模式 -->
> <property>
>   <name>mapreduce.job.ubertask.enable</name>
>   <value>true</value>
> </property>
> 
> <!-- uber模式中最大的mapTask数量，可向下修改  --> 
> <property>
>   <name>mapreduce.job.ubertask.maxmaps</name>
>   <value>9</value>
> </property>
> <!-- uber模式中最大的reduce数量，可向下修改 -->
> <property>
>   <name>mapreduce.job.ubertask.maxreduces</name>
>   <value>1</value>
> </property>
> <!-- uber模式中最大的输入数据量，默认使用dfs.blocksize 的值，可向下修改 -->
> <property>
>   <name>mapreduce.job.ubertask.maxbytes</name>
>   <value></value>
> </property>
> ```
>
> 

***

> **其他参数优化：**
>
> 1. 设置当map任务全部运行结束后才开始reduce任务（参数mapreduce.job.reduce.slowstart.completedmaps设置为1.0，默认0.05）。
> 2. 将当前Job的最大map任务尝试执行次数（参数mapreduce.map.maxattempts）和最大reduce任务尝试次数（参数mapreduce.reduce.maxattempts）都设置为1，默认为4。
> 3. 取消当前Job的map任务的推断执行（参数mapreduce.map.speculative设置为false）和reduce任务的推断执行（参数mapreduce.reduce.speculative设置为false），默认为。 
>

***

## 2.har归档

> 归档文件举例：
>
> ```shell
> #把/user/lyl/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/lyl/output路径下。
> hadoop archive -archiveName input.har -p  /user/lyl/input   /user/lyl/output
> 
> ```
>
> ***
>
> 查看归档
>
> ```shell
> hadoop fs -ls /user/lyl/output/input.har
> 
> #使用har协议查看归档文件可以看到原始的文件
> hadoop fs -ls har:///user/lyl/output/input.har
> ```
>
> ***
>
> 解归档文件
>
> ```shell
> #使用har协议解析归档文件并将解析出来的文件使用cp命令进行复制到另一个位置
> hadoop fs -cp har:///user/lyl/output/input.har/*    /user/lyl
> ```
>

***

## 3SequenceFile

> SequenceFile是由一系列的二进制k/v组成，如果为key为文件名，value为文件内容，可将大批小文件合并成一个大文件

***

## 4 CombineTextInputFormat

>  CombineTextInputFormat用于将多个小文件在切片过程中生成一个单独的切片或者少量的切片。